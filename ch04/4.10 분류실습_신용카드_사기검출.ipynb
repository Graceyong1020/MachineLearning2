{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2dddc07-afb6-4ad0-827e-311eb94b2d30",
   "metadata": {},
   "source": [
    "[데이터 일차 가공 및 모델 학습/예측/평가]\n",
    "\n",
    "\n",
    "* 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9eb95a-b1ea-488e-b5eb-c7ca09552643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "card_df = pd.read_csv('./creditcard.csv')\n",
    "card_df.head(3)\n",
    "\n",
    "# class => 0: 정상 거래, 1: 사기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6bd1c-9561-4ab6-bae7-bc3d2578f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_df.shape #31개 타겟값 포함한 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646de60-75bb-41f1-8316-6378ec4b1a79",
   "metadata": {},
   "source": [
    "* 원본 DataFrame은 유지하고 데이터 가공을 위한 DataFrame을 복사하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af98eda-5f26-4b7b-aab3-f0bfd3a017d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 인자로 입력받은 DataFrame을 복사 한 뒤 Time 컬럼만 삭제하고 복사된 DataFrame 반환\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a9dba-5182-4183-8c25-aac04e897d64",
   "metadata": {},
   "source": [
    "* 학습과 테스트 데이터 세트를 반환하는 함수 생성. 사전 데이터 처리가 끝난 뒤 해당 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7c445-a102-4d8e-978c-0a2cb4891edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 데이터 가공 후 학습과 테스트 데이터 세트를 반환하는 함수.\n",
    "def get_train_test_dataset(df=None):\n",
    "    # 인자로 입력된 DataFrame의 사전 데이터 가공이 완료된 복사 DataFrame 반환\n",
    "    df_copy = get_preprocessed_df(df)\n",
    "    \n",
    "    # DataFrame의 맨 마지막 컬럼이 레이블, 나머지는 피처들\n",
    "    X_features = df_copy.iloc[:, :-1] #맨 마지막 제외\n",
    "    y_target = df_copy.iloc[:, -1] # 맨 마지막 \n",
    "    \n",
    "    # train_test_split( )으로 학습과 테스트 데이터 분할. stratify=y_target으로 Stratified 기반 분할\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_features, y_target, test_size=0.3, random_state=0, stratify=y_target)\n",
    "    \n",
    "    # 학습과 테스트 데이터 세트 반환\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf79cc-ac6b-448b-8f02-f69930dd0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()/y_train.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eeed6f-34a0-424c-ac9c-ba8f54a743f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습 데이터 레이블 값 비율')\n",
    "print(y_train.value_counts()/y_train.shape[0] * 100)\n",
    "print('테스트 데이터 레이블 값 비율')\n",
    "print(y_test.value_counts()/y_test.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67b3e7-372e-423b-9f4f-400c19a624f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5d058-b902-43bd-aac9-2d4d0ebf75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 3장에서 사용한 get_clf_eval() 함수를 이용하여 평가 수행. \n",
    "get_clf_eval(y_test, lr_pred, lr_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44267e43-9a35-4f81-9fdb-c047b5f40b02",
   "metadata": {},
   "source": [
    "* 앞으로 피처 엔지니어링을 수행할 때마다 모델을 학습/예측/평가하므로 이를 위한 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79413a-db4a-480d-8c86-14407cfdda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자로 사이킷런의 Estimator객체와, 학습/테스트 데이터 세트를 입력 받아서 학습/예측/평가 수행.\n",
    "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "    model.fit(ftr_train, tgt_train) # 학습\n",
    "    pred = model.predict(ftr_test) # 예측\n",
    "    pred_proba = model.predict_proba(ftr_test)[:, 1] # 예측 확률 반환 \n",
    "    get_clf_eval(tgt_test, pred, pred_proba) # 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f192b-632e-4238-8fde-da9b16226e0a",
   "metadata": {},
   "source": [
    "* LightGBM 학습/예측/평가\n",
    "\n",
    "  - LightGBM 2.1.0 이상 버전에서 boost_from_average가 True가 Default가 됨. boost_from_average가\n",
    "    True일 경우 레이블 값이 극도로 불균형 분포를 이루는 경우 재현률 및 ROC-AUC 성능이 매우 저하됨. \n",
    "   레이블 값이 극도로 불균형할 경우 boost_from_average를 False로 설정하는 것이 유리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb4d42-47e9-4d9b-8791-34daf4997569",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9190dd-f6cb-4c17-b53a-b9b2b759bd96",
   "metadata": {},
   "source": [
    "[데이터 분포도 변환 후 모델 학습/예측/평가]\n",
    "\n",
    "\n",
    "* 중요 feature의 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd04587-9c04-44a4-b464-d8cf15517042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.xticks(range(0, 30000, 1000), rotation=60)\n",
    "sns.histplot(card_df['Amount'], bins=100, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ba852-fb46-4433-ad2a-53bf2807fbc5",
   "metadata": {},
   "source": [
    "* 데이터 사전 가공을 위한 별도의 함수에 StandardScaler를 이용하여 Amount 피처 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f6610-b21e-41eb-a52b-28793b616b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 사이킷런의 StandardScaler를 이용하여 정규분포 형태로 Amount 피처값 변환하는 로직으로 수정. \n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    scaler = StandardScaler()\n",
    "    amount_n = scaler.fit_transform(df_copy['Amount'].values.reshape(-1, 1))\n",
    "    # 변환된 Amount를 Amount_Scaled로 피처명 변경후 DataFrame맨 앞 컬럼으로 입력\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    # 기존 Time, Amount 피처 삭제\n",
    "    df_copy.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ee1de-8435-47fe-8dc9-64f30b174fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_df_test =get_preprocessed_df(card_df)\n",
    "card_df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffdbeb-219b-4fb8-aef1-7400c7dc4134",
   "metadata": {},
   "source": [
    "* StandardScaler 변환 후 로지스틱 회귀 및 LightGBM 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a0839-7ff0-4ae0-8149-64499f0b1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount를 정규분포 형태로 변환 후 로지스틱 회귀 및 LightGBM 수행. \n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba77e8-91e5-47cb-ab7f-86f8db522073",
   "metadata": {},
   "source": [
    "* Amount를 로그 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5c6ed-9b14-45cd-af28-222112eb6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    # 넘파이의 log1p( )를 이용하여 Amount를 로그 변환 \n",
    "    amount_n = np.log1p(df_copy['Amount'])\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a5b19-39c6-471f-b7f6-0be71b454a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.log(1e-1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68311ebc-0b5c-41db-887b-8c0624f125e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log1p 와 expm1 설명 \n",
    "import numpy as np\n",
    "\n",
    "print(1e-1000 == 0.0) \n",
    "\n",
    "print(np.log(1e-1000))\n",
    "\n",
    "print(np.log(1e-1000 + 1))\n",
    "print(np.log1p(1e-1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a34bee-82f4-49a9-beb5-d87a8f225457",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = np.log1p(100)\n",
    "var_2 = np.expm1(var_1)\n",
    "print(var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c910a-b05d-4b77-81e3-df92f1bac805",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae7c18-ee09-43c5-bcfd-dabcba7490fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(X_train['Amount_Scaled'], bins=50, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587edbd-8994-4dbf-8799-e46b6ef9b42e",
   "metadata": {},
   "source": [
    "[이상치 데이터 제거 후 모델 학습/예측/평가]\n",
    "\n",
    "* 각 피처들의 상관 관계를 시각화. 결정 레이블인 class 값과 가장 상관도가 높은 피처 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549627d-2a01-45d9-9d2d-bccc59b55190",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_df.corr() #데이터프레임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbab25-b4ff-4b36-b19f-714b46429289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "corr = card_df.corr() \n",
    "sns.heatmap(corr, annot=True, fmt='.1f',  cmap='RdBu')\n",
    "\n",
    "#x,y 축 상관관계를 히트맵으로 표현 (-1 ~ 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202cd412-1da0-4d37-b92a-c7c142fd6799",
   "metadata": {},
   "source": [
    "* Dataframe에서 outlier에 해당하는 데이터를 필터링하기 위한 함수 생성. outlier 레코드의 index를 반환함\n",
    "\n",
    "   - IQR(Inter Quantile Range) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af332b71-d0e0-4ade-94b9-325c6f73cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "    # fraud에 해당하는 column 데이터만 추출, 1/4 분위와 3/4 분위 지점을 np.percentile로 구함. \n",
    "    fraud = df[df['Class']==1][column]\n",
    "    quantile_25 = np.percentile(fraud.values, 25) # 1/4 지점 값 \n",
    "    quantile_75 = np.percentile(fraud.values, 75) # 3/4 지점 값 \n",
    "    # IQR을 구하고, IQR에 1.5를 곱하여 최대값과 최소값 지점 구함. \n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest_val = quantile_25 - iqr_weight\n",
    "    highest_val = quantile_75 + iqr_weight\n",
    "    # 최대값 보다 크거나, 최소값 보다 작은 값을 아웃라이어로 설정하고 DataFrame index 반환. \n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
    "    return outlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ebea2-57b3-4d5a-ada6-201b126db399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.min(card_df['V14'].values)\n",
    "#np.max(card_df['V14'].values) \n",
    "\n",
    "np.percentile(card_df['V14'].values, 75) # 3/4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10954d-23e3-483d-997f-0d4639fa5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(card_df['V14'].values, 100)\n",
    "np.max(card_df['V14'].values)\n",
    "quantile_25 = np.percentile(card_df['V14'].values, 25)\n",
    "quantile_75 = np.percentile(card_df['V14'].values, 75)\n",
    "print(quantile_25, quantile_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254b8cb-7c66-46bf-be29-199f5f167b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_index = get_outlier(df=card_df, column='V14', weight=1.5)\n",
    "print('이상치 데이터 인덱스:', outlier_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be55a8-5ad4-454a-bd97-38945985f4dd",
   "metadata": {},
   "source": [
    "* 로그 변환 후 V14 피처의 이상치 데이터를 삭제한 뒤 모델들을 재 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab097208-85cc-4cb0-8bb8-6bb2a9398090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_processed_df( )를 로그 변환 후 V14 피처의 이상치 데이터를 삭제하는 로직으로 변경. \n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    amount_n = np.log1p(df_copy['Amount'])\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "    # 이상치 데이터 삭제하는 로직 추가\n",
    "    outlier_index = get_outlier(df=df_copy, column='V14', weight=1.5)\n",
    "    df_copy.drop(outlier_index, axis=0, inplace=True) #index 4개만 삭제해야 하므로 axis=0\n",
    "    return df_copy\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e5622-bc44-42f9-8020-68021eb0dec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a774207-40b8-458f-804c-25cc59f27eac",
   "metadata": {},
   "source": [
    "[SMOTE 오버 샘플링 적용 후 모델 학습/예측/평가]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb169243-7506-4b1f-980d-ee3deaddd1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn \n",
    "\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324b08c-ec78-429f-8771-24fed67633ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd287e4d-b973-4122-aacc-55e5b8a3e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', X_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8d930-6f5d-4f90-8796-81191250ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "# ftr_train과 tgt_train 인자값이 SMOTE 증식된 X_train_over와 y_train_over로 변경됨에 유의\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d359682-594d-4122-af9a-668f491c373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27231513-8c88-4baa-b632-e86fe85942d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595150a6-3d88-4129-8794-dfcd07329ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train_over, ftr_test=X_test,\n",
    "                  tgt_train=y_train_over, tgt_test=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
